{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EHRDataloader import EHRdataFromPickles, EHRdataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 file found. Data will be split into train, validation and test.\n"
     ]
    }
   ],
   "source": [
    "print('1 file found. Data will be split into train, validation and test.')\n",
    "data = EHRdataFromPickles(root_dir = '../data/', \n",
    "                      file = 'toy.train', \n",
    "                      sort= False,\n",
    "                      test_ratio = 0.2, \n",
    "                      valid_ratio = 0.1,\n",
    "                      model='RNN') #No sort before splitting\n",
    "\n",
    "# Dataloader splits\n",
    "train, test, valid = data.__splitdata__() #this time, sort is true\n",
    "# can comment out this part if you dont want to know what's going on here\n",
    "# print(colored(\"\\nSee an example data structure from training data:\", 'green'))\n",
    "# print(data.__getitem__(35, seeDescription = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for ii in range(len(train)):\n",
    "    label=train[ii][1]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3511, 0: 3489})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print sizes of train test and valid datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 2000, 1000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test),len(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: 2569\n",
      "Heart Failure: 1\n",
      "# of visits: 154\n",
      " list of visit_time (since last time): [12753]\n",
      " list of codes corresponding to visit: [2836]\n"
     ]
    }
   ],
   "source": [
    "## example dataset for patient 0 and visit 0\n",
    "patient=0\n",
    "visit=0\n",
    "print(\"Patient ID:\", train[patient][0])\n",
    "print(\"Heart Failure:\", train[patient][1])\n",
    "print(\"# of visits:\", len(train[patient][2]))\n",
    "\n",
    "print(f' list of visit_time (since last time): {train[patient][2][visit][0]}')\n",
    "print(f' list of codes corresponding to visit: {train[patient][2][visit][1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "pack_pad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:02<00:00, 88.38it/s] \n",
      "  9%|▉         | 3/32 [00:00<00:01, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " creating the list of valid minibatches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 84.88it/s]\n",
      "  3%|▎         | 2/63 [00:00<00:03, 17.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " creating the list of test minibatches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 87.90it/s]\n"
     ]
    }
   ],
   "source": [
    "## Understand EHRdataloader\n",
    "train_mbs = list(tqdm(EHRdataloader(train, batch_size = batch_size, packPadMode = pack_pad)))\n",
    "print (' creating the list of valid minibatches')\n",
    "valid_mbs = list(tqdm(EHRdataloader(valid, batch_size = batch_size, packPadMode = pack_pad)))\n",
    "print (' creating the list of test minibatches')\n",
    "test_mbs = list(tqdm(EHRdataloader(test, batch_size = batch_size, packPadMode = pack_pad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models as model \n",
    "#from embedding import EHRembeddings \n",
    "# from EHREmb import EHREmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "#construct a whole embedding class from pytorch nn.module\n",
    "#then we call this class in models after we define it \n",
    "class EHREmbeddings(nn.Module):\n",
    "    #initialization and then the forward and things\n",
    "    #DRNN has no bi, QRNN no bi, TLSTM has no bi, but DRNN has other cell-types \n",
    "    #cel_type are different for each model variation \n",
    "    def __init__(self, input_size, embed_dim ,hidden_size, n_layers=1,dropout_r=0.1,cell_type='LSTM', bii=False, time=False , preTrainEmb='', packPadMode = True):\n",
    "        super(EHREmbeddings, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_r = dropout_r\n",
    "        self.cell_type = cell_type\n",
    "        self.time=time\n",
    "        self.preTrainEmb=preTrainEmb\n",
    "        self.packPadMode = packPadMode\n",
    "        if bii: \n",
    "            self.bi=2 \n",
    "        else: \n",
    "            self.bi=1\n",
    "            \n",
    "        if len(input_size)==1:\n",
    "            self.multi_emb=False\n",
    "            if len(self.preTrainEmb)>0:\n",
    "                emb_t= torch.FloatTensor(np.asmatrix(self.preTrainEmb))\n",
    "                self.embed= nn.Embedding.from_pretrained(emb_t)#,freeze=False) \n",
    "                self.in_size= embed_dim ### need to be updated to be automatically capyured from the input\n",
    "            else:\n",
    "                input_size=input_size[0]\n",
    "                self.embed= nn.Embedding(input_size, self.embed_dim,padding_idx=0)#,scale_grad_by_freq=True)\n",
    "                self.in_size= embed_dim\n",
    "        else:\n",
    "            if len(input_size)!=3: \n",
    "                raise ValueError('the input list is 1 length')\n",
    "            else: \n",
    "                self.multi_emb=True\n",
    "                self.diag=self.med=self.oth=1\n",
    "\n",
    "        #self.emb = self.embed.weight  LR commented Jul 10 19\n",
    "        if self.time: self.in_size= self.in_size+1 \n",
    "               \n",
    "        if self.cell_type == \"GRU\":\n",
    "            self.cell = nn.GRU\n",
    "        elif self.cell_type == \"RNN\":\n",
    "            self.cell = nn.RNN\n",
    "        elif self.cell_type == \"LSTM\":\n",
    "            self.cell = nn.LSTM\n",
    "        elif self.cell_type == \"QRNN\":\n",
    "            from torchqrnn import QRNN\n",
    "            self.cell = QRNN\n",
    "        elif self.cell_type == \"TLSTM\":\n",
    "            from tplstm import TPLSTM\n",
    "            self.cell = TPLSTM \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "       \n",
    "        if self.cell_type == \"QRNN\": \n",
    "            self.bi=1 ### QRNN not support Bidirectional, DRNN should not be BiDirectional either.\n",
    "            self.rnn_c = self.cell(self.in_size, self.hidden_size, num_layers= self.n_layers, dropout= self.dropout_r)\n",
    "        elif self.cell_type == \"TLSTM\":\n",
    "            self.bi=1 \n",
    "            self.rnn_c = self.cell(self.in_size, hidden_size)\n",
    "        else:\n",
    "            self.rnn_c = self.cell(self.in_size, self.hidden_size, num_layers=self.n_layers, dropout= self.dropout_r, bidirectional=bii, batch_first=True)\n",
    "         \n",
    "        self.out = nn.Linear(self.hidden_size*self.bi,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "      \n",
    "                            \n",
    "    #let's define this class method\n",
    "    def EmbedPatients_MB(self,mb_t, mtd): #let's define this\n",
    "        self.bsize=len(mb_t) ## no of pts in minibatch\n",
    "        \n",
    "        embedded = self.embed(mb_t)  ## Embedding for codes\n",
    "        embedded = torch.sum(embedded, dim=2) \n",
    "        if self.time:\n",
    "            mtd_t= Variable(torch.stack(mtd,0))\n",
    "            if use_cuda: \n",
    "                mtd_t.cuda()\n",
    "            out_emb= torch.cat((embedded,mtd_t),dim=2)\n",
    "        else:\n",
    "            out_emb= embedded\n",
    "        if use_cuda:\n",
    "            out_emb.cuda()        \n",
    "        return out_emb\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1:RNN & Variations: GRU, LSTM, Bi-RNN, Bi-GRU, Bi-LSTM\n",
    "class EHR_RNN(EHREmbeddings):\n",
    "    def __init__(self,input_size,embed_dim, hidden_size, n_layers=1,dropout_r=0.1,cell_type='GRU',bii=False ,time=False, preTrainEmb='',packPadMode = True):\n",
    "       \tEHREmbeddings.__init__(self,input_size, embed_dim ,hidden_size, n_layers=n_layers, dropout_r=dropout_r, cell_type=cell_type, bii=bii, time=time , preTrainEmb=preTrainEmb, packPadMode=packPadMode)\n",
    "    #embedding function goes here \n",
    "    \n",
    "    def EmbedPatient_MB(self, input, mtd):\n",
    "        return EHREmbeddings.EmbedPatients_MB(self, input, mtd)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        h_0 = Variable(torch.rand(self.n_layers*self.bi,self.bsize, self.hidden_size))\n",
    "        if use_cuda: \n",
    "            h_0.cuda()\n",
    "        if self.cell_type == \"LSTM\":\n",
    "            result = (h_0,h_0)\n",
    "        else: \n",
    "            result = h_0\n",
    "        return result\n",
    "    \n",
    "    def forward(self, input, x_lens, mtd):\n",
    "        x_in  = self.EmbedPatient_MB(input, mtd) \n",
    "        ### uncomment the below lines if you like to initiate hidden to random instead of Zero which is the default\n",
    "        #h_0= self.init_hidden()\n",
    "        #if use_cuda: h_0.cuda()\n",
    "        if self.packPadMode: \n",
    "            x_inp = nn.utils.rnn.pack_padded_sequence(x_in,x_lens,batch_first=True)   \n",
    "            output, hidden = self.rnn_c(x_inp)#,h_0) \n",
    "        else:\n",
    "            output, hidden = self.rnn_c(x_in)#,h_0) \n",
    "        \n",
    "        if self.cell_type == \"LSTM\":\n",
    "            hidden=hidden[0]\n",
    "        if self.bi==2:\n",
    "            output = self.sigmoid(self.out(torch.cat((hidden[-2],hidden[-1]),1)))\n",
    "        else:\n",
    "            output = self.sigmoid(self.out(hidden[-1]))\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=[30000]\n",
    "embed_dim=128\n",
    "hidden_size=128\n",
    "n_layers=2\n",
    "dropout_r=0.2\n",
    "patience=3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EHR_RNN(input_size= input_size, \n",
    "                          embed_dim=embed_dim, \n",
    "                          hidden_size= hidden_size,\n",
    "                          dropout_r=dropout_r) \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                           lr=0.01, \n",
    "                           weight_decay=1e-04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss0.5003598928451538\n",
      "Epoch 1, Loss0.1714329868555069\n",
      "Epoch 2, Loss0.41065284609794617\n",
      "Epoch 3, Loss0.15212054550647736\n",
      "Epoch 4, Loss0.3622772991657257\n",
      "Epoch 5, Loss0.1880924552679062\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for ep in range(epochs):\n",
    "    for i,batch in enumerate(train_mbs):\n",
    "        sample, label_tensor, seq_l, mtd = batch\n",
    "        \n",
    "        model.train() ## LR added Jul 10, that is the right implementation\n",
    "        model.zero_grad()\n",
    "        output = model(sample,seq_l, mtd)   \n",
    "        loss = criterion(output, label_tensor.ravel())    \n",
    "        loss.backward()   \n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {ep}, Loss {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
